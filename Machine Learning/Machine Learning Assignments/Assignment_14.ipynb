{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. What is the concept of supervised learning? What is the significance of the name?**\n",
    "\n",
    "**Solution:-** Supervised machine learning is a method of solving machine learning problems by training a labelled data. Labelled data means labelled target feature/ value.\n",
    "\n",
    "Significance of the name is that the name itself explains that there will be some form of supervision working on machine learning. The labelled data acts as a supervision for machine learning as class labels or target variable values have been manually fed or generated from past records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. In the hospital sector, offer an example of supervised learning.**\n",
    "\n",
    "**Solution:-** Several surgeries and therapies like chemotherapy are last resort method to patients debilitating them. These surgeries often run a risk of death if a combination of parameters like oxygen saturation level are not within limits. Crucial time is saved by feeding the patient's readings against such parameters into supervised machine learning models that can classify the survivability of a patient post surgery fast and all allow the model to learn over time. \n",
    "\n",
    "The algorithm measures its accuracy through the loss function, adjusting until the error has been sufficiently minimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Give three supervised learning examples.**\n",
    "\n",
    "**Solution:-**\n",
    "\n",
    "Example of Supervised Learning Algorithms are:\n",
    "\n",
    "1. Linear Regression.\n",
    "2. Nearest Neighbor.\n",
    "3. Gaussian Naive Bayes.\n",
    "4. Decision Trees.\n",
    "5. Support Vector Machine (SVM)\n",
    "6. Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. In supervised learning, what are classification and regression?**\n",
    "\n",
    "**Solution:-** Classification is a task performed using supervised learning where the target or dependent variable values is labelled data come from a countably finite dataset.\n",
    "\n",
    "Regression is a task performed using supervised learning where the target or dependent variable values in the labelled data come from a countably infinite set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Give some popular classification algorithms as examples.**\n",
    "\n",
    "**Solution:-**\n",
    "\n",
    "1. Naive Bayes classifier\n",
    "2. Random Forest classifier\n",
    "3. Support Vector classifier.\n",
    "4. k-Nearest Neighbors\n",
    "5. Decision Trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Briefly describe the SVM model.**\n",
    "\n",
    "**Solution:-** \n",
    "A support vector machine (SVM) is a supervised machine learning model that uses classification algorithms for two-group classification problems. After giving an SVM model sets of labeled training data for each category, they're able to categorize new text.\n",
    "\n",
    "SVM or Support Vector Machine model is a machine learning model that can be used for classification and regression model. It relies on finding a hyperplane and support vectors for classification such that the two data points on the outskirts of their own classes of linearly classifiable data. These support vectors act as margins on either side of the hyperplane. Support vectors are chosen such that the margin on either side of hyperplane is maximum.\n",
    "\n",
    "Support Vector Machine models are not only used for binary linear classification, but can also be used for multiclass non linear classification. Support Vector algorithms use kernels like polynomial kernels, quadratic kernels, string kernels and genome kernels for kernelization which is just like feature transformation.\n",
    "\n",
    "![image](https://www.researchgate.net/publication/332248436/figure/fig5/AS:864758303563793@1583185854982/Support-Vector-Machine-visualization.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. In SVM, what is the cost of misclassification?**\n",
    "\n",
    "**Solution:-** Zeta is the variable that becomes the cost of misclassification. \n",
    "\n",
    "In cost-sensitive learning instead of each instance being either correctly or incorrectly classified, each class (or instance) is given a misclassification cost. Thus, instead of trying to optimize the accuracy, the problem is then to minimize the total misclassification cost.\n",
    "\n",
    "Its value is determined by the distance of a misclassified point beyond or inside a margin. 0 value of zeta would mean correct classification while a non zero value would mean misclassification on one side of the main hyperplane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. In the SVM model, define Support Vectors.**\n",
    "\n",
    "**Solution:-** In SVM model, the hyperplane is calculated such that it maximises the margin(margin is set such that one margin touches data point of one class and one margin touches data point of another class) or maximises the distance between hyperplane and margin and then classifies the data points as widely as possible.\n",
    "\n",
    "Support vectors are data points that are closer to the hyperplane and influence the position and orientation of the hyperplane. Using these support vectors, we maximize the margin of the classifier. Deleting the support vectors will change the position of the hyperplane. These are the points that help us build our SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. In the SVM model, define the kernel.**\n",
    "\n",
    "**Solution:-** \n",
    "SVM algorithms use a set of mathematical functions that are defined as the kernel. The function of kernel is to take data as input and transform it into the required form. These functions can be different types. For example linear, nonlinear, polynomial, radial basis function (RBF), and sigmoid.\n",
    "\n",
    "In the SVM model, different mathematical functions can be used in place of the (transpose(xi)*x) of the dual problem for various implicit feature transformations. Such mathematical functions that can make SVM work with nearly any form of non linear classification and regression is called the kernel. For example, String kernels can be used to make SVM usable for NLP applications.\n",
    "\n",
    "f(x)=N Xi αi yi (xiTx) + b\n",
    "\n",
    "![image](https://www.aionlinecourse.com/uploads/tutorials/2019/07/11_Kernel_SVM_5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. What are the factors that influence SVM's effectiveness?**\n",
    "\n",
    "**Solution:-** SVM or Support Vector Machine is a linear model for classification and regression problems. It can solve linear and non-linear problems and work well for many practical problems. The idea of SVM is simple: The algorithm creates a line or a hyperplane which separates the data into classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11. What are the benefits of using the SVM model?**\n",
    "\n",
    "**Solution:-**\n",
    "\n",
    "1. SVM is works well in high dimensional spaces.\n",
    "\n",
    "2. Outliers have little impact in case of kernel SVMs.\n",
    "\n",
    "3. Implicit kernelization helps SVM work and come up with non linear decision surfaces.\n",
    "\n",
    "4. High generalizability due to margins\n",
    "5. SVM works relatively well when there is a clear margin of separation between classes.\n",
    "6. SVM is effective in cases where the number of dimensions is greater than the number of samples.\n",
    "7. SVM is relatively memory efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12. What are the drawbacks of using the SVM model?**\n",
    "\n",
    "**Solution:-**\n",
    "\n",
    " * Finding or coming up with problem specific kernels for best performance of SVM is difficult.\n",
    " * SVM algorithm is not suitable for large data sets. \n",
    " * No inherent way of getting feature importance.\n",
    " * SVM does not perform very well when the data set has more noise i.e. target classes are overlapping.\n",
    " * Built model has low interpretability\n",
    " * In cases where the number of features for each data point exceeds the number of training data samples, the SVM will underperform.\n",
    " * Presence of two hyperparameters makes tuning time large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**13. Notes should be written on**\n",
    "\n",
    "**Solution:-**\n",
    "\n",
    "**A. The kNN algorithm has a validation flaw.**\n",
    "The relatively low accuracy of kNN is caused by several factors. One of them is that every characteristic of the method has the same result on calculating distance. The solution of this problem is to give weight to each data characteristic.\n",
    "\n",
    "**B. In the kNN algorithm, the k value is chosen.** The optimal K value usually found is the square root of N, where N is the total number of samples. Use an error plot or accuracy plot to find the most favorable K value. KNN performs well with multi-label classes, but you must be aware of the outliers.\n",
    "**C. A decision tree with inductive bias** Shorter trees are preferred over longer ones. Trees that place high information gain attributes close to the root are preferred over those that do not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**14. What are some of the benefits of the kNN algorithm?**\n",
    "\n",
    "**Solution:-**\n",
    "Advantages of KNN are:\n",
    "- Quick calculation time.\n",
    "- Simple algorithm – to interpret.\n",
    "- Versatile – useful for regression and classification.\n",
    "- High accuracy – you do not need to compare with better-supervised learning models.\n",
    "- Time and Space complexity low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**15. What are some of the kNN algorithm's drawbacks?**\n",
    "\n",
    "**Solution:-**\n",
    "\n",
    "Disadvantages of KNN are:\n",
    "- Accuracy depends on the quality of the data.\n",
    "- With large data, the prediction stage might be slow.\n",
    "- Sensitive to the scale of the data and irrelevant features.\n",
    "- Require high memory – need to store all of the training data.\n",
    "- Given that it stores all of the training, it can be computationally expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**16. Explain the decision tree algorithm in a few words.**\n",
    "\n",
    "**Solution:-** \n",
    "\n",
    "A decision tree is a graphical representation of all the possible solutions to a decision based on certain threshold conditions. Tree models where the target variable can take a finite set of values are called classification trees and target variable can take continuous values (numbers) are called regression trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**17. What is the difference between a node and a leaf in a decision tree?**\n",
    "\n",
    "**Solution:-** \n",
    "A decision tree is a flowchart-like structure in which each internal node represents a \"test\" on an attribute (e.g. whether a coin flip comes up heads or tails), each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes).\n",
    "\n",
    "Node in a decision tree is a collection of data points for which decision has to be made whether to split or not, and how to split using a mathematical function.\n",
    "\n",
    "Leaf in a decision tree is a terminating node or a terminating vector, beyond which no splits will be done.\n",
    "\n",
    "![IMAGE](https://miro.medium.com/max/1400/1*n6CEhoqYYLVtLJDzs40ezg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**18. What is a decision tree's entropy?**\n",
    "\n",
    "**Solution:-** Entropy helps us to build an appropriate decision tree for selecting the best splitter.\n",
    "Entropy can be defined as a measure of the purity of the sub split. Entropy always lies between 0 to 1. The entropy of any split can be calculate by this formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**19. In a decision tree, define knowledge gain.**\n",
    "\n",
    "**Solution:-** Information gain is the reduction in entropy or surprise by transforming a dataset and is often used in training decision trees. Information gain is calculated by comparing the entropy of the dataset before and after a transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**20. Choose three advantages of the decision tree approach and write them down.** \n",
    "\n",
    "**Solution:-**\n",
    "\n",
    "Advantages of Decision Trees :\n",
    "\n",
    "- Easy to read and interpret. One of the advantages of decision trees is that their outputs are easy to read and interpret without requiring statistical knowledge.\n",
    "- Easy to prepare.\n",
    "- Less data cleaning required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**21. Make a list of three flaws in the decision tree process.**\n",
    "\n",
    "**Solution:-**\n",
    "\n",
    "Issues in Decision Tree Learning :\n",
    "\n",
    "- Overfitting the data.\n",
    "- Guarding against bad attribute choices.\n",
    "- Handling continuous valued attributes.\n",
    "- Handling missing attribute values.\n",
    "- Handling attributes with differing costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**22. Briefly describe the random forest model.**\n",
    "\n",
    "**Solution:-** The random forest is an aaggregation ensemble model,  classification algorithm consisting of many decisions trees.\n",
    "\n",
    "Multiple base learner decision trees are trained on subsets of data and each comes up with its own classification result. At the end, a majority vote is used to come to the final conclusion regarding the true classification result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
